{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6960,"databundleVersionId":44258,"sourceType":"competition"},{"sourceId":4047,"sourceType":"datasetVersion","datasetId":2410},{"sourceId":4420,"sourceType":"datasetVersion","datasetId":1655},{"sourceId":9237085,"sourceType":"datasetVersion","datasetId":5551787}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport copy\nimport gc\nimport time\nfrom pandas.tseries.holiday import USFederalHolidayCalendar as calendar\nfrom sklearn.decomposition import PCA\nimport geopandas as gpd\n\nimport tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Ridge,Lasso\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cluster import DBSCAN,KMeans\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nimport catboost\nfrom catboost import CatBoostRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nimport lightgbm as lgb\n\nimport torch \nimport torch.nn as nn\nfrom torch.utils.data import DataLoader,Dataset\nfrom torch.nn import functional as F \nfrom scipy.spatial.distance import pdist, squareform\n%matplotlib inline\nfrom joblib import dump, load\nimport geopandas as gpd\nfrom sklearn.model_selection import KFold\nfrom shapely.geometry import Polygon,Point\n\n\nkf=KFold(n_splits=5,shuffle=True,random_state=2024)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-03T11:16:04.389491Z","iopub.execute_input":"2024-09-03T11:16:04.390090Z","iopub.status.idle":"2024-09-03T11:16:04.411889Z","shell.execute_reply.started":"2024-09-03T11:16:04.390036Z","shell.execute_reply":"2024-09-03T11:16:04.409984Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"#############################################\n#########  想看数据路径就用下面的代码   #########\n#############################################\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        ","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:16:17.586274Z","iopub.execute_input":"2024-09-03T11:16:17.586739Z","iopub.status.idle":"2024-09-03T11:16:17.592469Z","shell.execute_reply.started":"2024-09-03T11:16:17.586696Z","shell.execute_reply":"2024-09-03T11:16:17.591093Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"# 读取数据\n\n+ train = 训练集\n+ test = 测试集\n+ train_addition = 天气数据\n+ test_ additon = 天气数据\n+ train_aug = osrm 道路数据\n+ test_aug = osrm 道路数据\n\n+ ori_train = 训练数据副本\n+ test_train = 测试数据副本\n\n不用管，可以拿最终的train和test训练，可以一直执行到下一段MarkDown文本","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/nyc-taxi-trip-duration/train.zip\")\ntest=pd.read_csv(\"/kaggle/input/nyc-taxi-trip-duration/test.zip\")","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:16:22.080078Z","iopub.execute_input":"2024-09-03T11:16:22.081401Z","iopub.status.idle":"2024-09-03T11:16:31.309128Z","shell.execute_reply.started":"2024-09-03T11:16:22.081343Z","shell.execute_reply":"2024-09-03T11:16:31.307796Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"train_aug=pd.read_csv('/kaggle/input/nyc-taxi-trip-noisy/train_augmented.csv')\ntest_aug=pd.read_csv('/kaggle/input/nyc-taxi-trip-noisy/test_augmented.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:16:31.311991Z","iopub.execute_input":"2024-09-03T11:16:31.312865Z","iopub.status.idle":"2024-09-03T11:16:35.487507Z","shell.execute_reply.started":"2024-09-03T11:16:31.312800Z","shell.execute_reply":"2024-09-03T11:16:35.486144Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"train=train.merge(train_aug,on='id',how='left')\ntest=test.merge(test_aug,on='id',how='left')","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:16:35.489358Z","iopub.execute_input":"2024-09-03T11:16:35.489904Z","iopub.status.idle":"2024-09-03T11:16:39.092103Z","shell.execute_reply.started":"2024-09-03T11:16:35.489841Z","shell.execute_reply":"2024-09-03T11:16:39.090783Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"train=pd.concat([train,pd.read_csv(\"/kaggle/input/nyc-addtion/Addition.csv\")],axis=1)\ntest=pd.concat([test,pd.read_csv(\"/kaggle/input/nyc-addtion/New York City Taxi Trip Duration/Addition_test.csv\")],axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:16:39.094828Z","iopub.execute_input":"2024-09-03T11:16:39.095271Z","iopub.status.idle":"2024-09-03T11:16:41.210650Z","shell.execute_reply.started":"2024-09-03T11:16:39.095227Z","shell.execute_reply":"2024-09-03T11:16:41.209241Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"ori_train,ori_test=copy.deepcopy(train),copy.deepcopy(test)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:16:41.212362Z","iopub.execute_input":"2024-09-03T11:16:41.213956Z","iopub.status.idle":"2024-09-03T11:16:41.810663Z","shell.execute_reply.started":"2024-09-03T11:16:41.213884Z","shell.execute_reply":"2024-09-03T11:16:41.808781Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"weather = pd.read_csv(\"/kaggle/input/weather-data-in-new-york-city-2016/weather_data_nyc_centralpark_2016(1).csv\")\nweather['precipitation'] = pd.to_numeric(weather['precipitation'], errors='coerce')\nweather['snow fall'] = pd.to_numeric(weather['snow fall'], errors='coerce')\nweather['snow depth'] = pd.to_numeric(weather['snow depth'], errors='coerce')","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:16:41.812645Z","iopub.execute_input":"2024-09-03T11:16:41.813169Z","iopub.status.idle":"2024-09-03T11:16:41.829941Z","shell.execute_reply.started":"2024-09-03T11:16:41.813110Z","shell.execute_reply":"2024-09-03T11:16:41.828447Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"# 下面是聚类点数据，可以不使用","metadata":{}},{"cell_type":"code","source":"test_C=load(\"/kaggle/input/nyc-addtion/cluster (2).pkl\")\ntrain['in_Cluster']=test_C.predict(train[['pickup_latitude','pickup_longitude']].values)\ntrain['out_Cluster']=test_C.predict(train[['dropoff_latitude','dropoff_longitude']].values)\ntest['in_Cluster']=test_C.predict(test[['pickup_latitude','pickup_longitude']].values)\ntest['out_Cluster']=test_C.predict(test[['dropoff_latitude','dropoff_longitude']].values)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:16:41.831615Z","iopub.execute_input":"2024-09-03T11:16:41.832128Z","iopub.status.idle":"2024-09-03T11:16:43.854893Z","shell.execute_reply.started":"2024-09-03T11:16:41.832068Z","shell.execute_reply":"2024-09-03T11:16:43.853669Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator KMeans from version 1.0.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 数据清洗\n\n+ 把自己的步骤导入进来","metadata":{"execution":{"iopub.status.busy":"2024-09-03T10:23:20.670624Z","iopub.execute_input":"2024-09-03T10:23:20.671063Z","iopub.status.idle":"2024-09-03T10:23:20.711078Z","shell.execute_reply.started":"2024-09-03T10:23:20.671006Z","shell.execute_reply":"2024-09-03T10:23:20.709305Z"}}},{"cell_type":"code","source":"def limit_range(train):\n    train = train[train['pickup_longitude'].between(-75, -73)]\n    train = train[train['pickup_latitude'].between(40, 42)]\n    train = train[train['dropoff_longitude'].between(-75, -73)]\n    train = train[train['dropoff_latitude'].between(40, 42)]\n    return train","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:26:58.700431Z","iopub.execute_input":"2024-09-03T11:26:58.700874Z","iopub.status.idle":"2024-09-03T11:26:58.709754Z","shell.execute_reply.started":"2024-09-03T11:26:58.700833Z","shell.execute_reply":"2024-09-03T11:26:58.708038Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"train,test=limit_range(train),limit_range(test)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:27:08.901561Z","iopub.execute_input":"2024-09-03T11:27:08.902051Z","iopub.status.idle":"2024-09-03T11:27:11.353145Z","shell.execute_reply.started":"2024-09-03T11:27:08.901972Z","shell.execute_reply":"2024-09-03T11:27:11.351340Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"# 所有工作做完之后\ntest_index=test.index # 清洗后的索引\ntrain_index=train.index","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:27:34.577379Z","iopub.execute_input":"2024-09-03T11:27:34.577858Z","iopub.status.idle":"2024-09-03T11:27:34.584274Z","shell.execute_reply.started":"2024-09-03T11:27:34.577813Z","shell.execute_reply":"2024-09-03T11:27:34.582368Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"train.reset_index(inplace=True) # 做也可以不做也可以\ntest.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:27:51.567384Z","iopub.execute_input":"2024-09-03T11:27:51.567885Z","iopub.status.idle":"2024-09-03T11:27:51.580570Z","shell.execute_reply.started":"2024-09-03T11:27:51.567840Z","shell.execute_reply":"2024-09-03T11:27:51.578944Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"# 特征工程\n\n+ 这里面替换成自己的就行\n+ 或者有些一些想要保留的就直接保留了\n+ 添加自己的特征列，最后在features里面输入就行\n\n+ 对于train的处理： train=process(train)\n+ 对于test的处理： test=process(test,False)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T10:22:50.652664Z","iopub.execute_input":"2024-09-03T10:22:50.653200Z","iopub.status.idle":"2024-09-03T10:22:50.662280Z","shell.execute_reply.started":"2024-09-03T10:22:50.653153Z","shell.execute_reply":"2024-09-03T10:22:50.660599Z"}}},{"cell_type":"code","source":"def process(train,is_Train=True,is_outrange=False):\n\n    ########################################################################################################\n    ############                      时间特征                               ###############################\n    ########################################################################################################\n\n    def rush_hour_f(row):\n        rhour = row['real_hour']\n        if (6 <= rhour) & (rhour <= 10):\n            return 1\n        if (10 < rhour) & (rhour < 16):\n            return 2\n        if (16 <= rhour) & (rhour <= 20):\n            return 3\n        return 0\n    def people(data):\n        if data==0:\n            return 1\n        if data>6:return 6\n        return data\n    train['pc']=train['passenger_count'].apply(people)\n    \n\n\n    encoder.fit(train['store_and_fwd_flag'])\n    train['store_and_fwd_flag'] = encoder.transform(train['store_and_fwd_flag'])\n    \n    train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])\n    train['month'] = train['pickup_datetime'].dt.month\n    train['weekday'] = train['pickup_datetime'].dt.weekday\n    train['hour'] = train['pickup_datetime'].dt.hour\n    train['minute'] = train['pickup_datetime'].dt.minute\n    train['minute_of_day'] = train['hour'] * 60 + train['minute']\n    train['real_hour'] = train['minute_of_day'] / 60\n        #for weather\n    train['year'] = train['pickup_datetime'].dt.year\n    train['day'] = train['pickup_datetime'].dt.day\n    train['rush_hour'] = train.apply(rush_hour_f, axis=1)\n\n    cal = calendar()\n    holidays = cal.holidays(start=pd.Timestamp(2015,12,31), end=pd.Timestamp(2017,1,1))\n    H=[[i.month,i.day] for i in holidays]\n    train['is_weekend']=train['weekday'].apply(lambda x:1 if x>4 else 0)\n    for i,j in H:\n        # 这里特别值得注意，查询返回的是一个视图\n        # 对视图的修改并不会返回到原始上\n        # 因此，我们需要做的是，采用iloc获得条件查询的index并进行修改\n        train.iloc[train[(train['month']==i)&(train['day']==j)].index,-1]=1\n    encoder.fit(train['is_weekend'])\n    train['is_weekend'] = encoder.transform(train['is_weekend'])\n    \n    ########################################################################################################\n    ############                      空间特征                               ###############################\n    ########################################################################################################\n    AVG_EARTH_RADIUS =6369\n    def ft_haversine_distance(lat1, lng1, lat2, lng2):\n    # Haversine距离，用于测量大地距离\n        lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n        lat = lat2 - lat1\n        lng = lng2 - lng1\n        d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n        h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n        return h\n\n    def ft_degree(lat1,log1,lat2,log2):\n        # 用于计算坐标方位\n        lng_delta_rad = np.radians(log2 - log1)\n        lat1, lng1, lat2, lng2 = map(np.radians, (lat1,log1,lat2,log2))\n        y = np.sin(lng_delta_rad) * np.cos(lat2)\n        x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n        return np.degrees(np.arctan2(y, x))     \n    def real_km(lat1,log1,lat2,log2):\n        theta=np.cos(np.mean(lat1+lat2))\n        return np.abs(lat1-lat2)*111.1+np.abs(log1-log2)*111.1*theta\n    def direction_bins(data,k=16):\n        node=360//k\n        data+=180\n        for i in range(k):\n            if node*i<=data<node*(i+1):\n                return i\n        return i\n    def Type(data):\n        if data<=0.1:\n            return 0\n        if data<=1:\n            return 1\n        if data<=3:\n            return 2\n        return 3\n        \n    train['distance_have']=ft_haversine_distance(train['pickup_latitude'].values,\n                                                     train['pickup_longitude'].values, \n                                                     train['dropoff_latitude'].values,\n                                                     train['dropoff_longitude'].values)\n    train['distance']=train['distance']/1000\n    train['distance_type']=train['distance'].apply(Type)\n\n    train['distance_log']=np.log(train.distance+1)\n    train['duration_log']=np.log(train.duration+1)\n    train['direction'] = ft_degree(train['pickup_latitude'].values,\n                                    train['pickup_longitude'].values,\n                                    train['dropoff_latitude'].values,\n                                    train['dropoff_longitude'].values)\n\n    train['direction_bins']=train['direction'].apply(direction_bins)\n    train['real_km']=real_km(train['pickup_latitude'].values,\n                                    train['pickup_longitude'].values,\n                                    train['dropoff_latitude'].values,\n                                    train['dropoff_longitude'].values)\n    train['ave_speed']=train.distance/(train.duration+1e-3)*3600\n    train['day_of_year']=train['day']+(train['month']-1)*31\n    if is_Train:\n        train = train[(train.trip_duration < 1000000)] if not is_outrange else train\n        duration = train['trip_duration']\n        train['speed'] = train.distance_have / duration * 2236.936292\n        train['trip_duration'] = np.log(train['trip_duration'].values)\n        \n    ########################################################################################################\n    ############                      附带信息特征                               ###############################\n    ########################################################################################################\n        #NYS max speed limit 55mph\n\n    weather[\"date\"] = pd.to_datetime(weather[\"date\"],format='%d-%m-%Y')\n    weather['year'] = weather['date'].dt.year\n    weather_2016 = weather[weather[\"year\"] == 2016]\n    weather_2016.drop([\"year\"], axis=1, inplace=True)\n    \n    train['date']=pd.to_datetime(train[['year','month','day']],errors='coerce')\n    left_merge = pd.merge(left=train, right=weather_2016, on=\"date\", how=\"left\")\n    train = left_merge.loc[:, left_merge.columns != 'date']\n    \n    if not is_outrange:\n        train['in_Cluster']=train['in_Cluster'].astype(str)\n        train['out_Cluster']=train['out_Cluster'].astype(str)\n\n        encoder.fit(train['in_Cluster'])\n        train['in_Cluster']=encoder.transform(train['in_Cluster'])\n        encoder.fit(train['out_Cluster'])\n        train['out_Cluster']=encoder.transform(train['out_Cluster'])\n    \n    return train\n        ","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:17:23.163891Z","iopub.execute_input":"2024-09-03T11:17:23.164413Z","iopub.status.idle":"2024-09-03T11:17:23.206869Z","shell.execute_reply.started":"2024-09-03T11:17:23.164365Z","shell.execute_reply":"2024-09-03T11:17:23.205521Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"train,test=process(train),process(test,False)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:17:23.492205Z","iopub.execute_input":"2024-09-03T11:17:23.492679Z","iopub.status.idle":"2024-09-03T11:18:26.554988Z","shell.execute_reply.started":"2024-09-03T11:17:23.492635Z","shell.execute_reply":"2024-09-03T11:18:26.553493Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":75,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2917683.py:114: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train['speed'] = train.distance_have / duration * 2236.936292\n/tmp/ipykernel_36/2917683.py:115: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train['trip_duration'] = np.log(train['trip_duration'].values)\n/tmp/ipykernel_36/2917683.py:127: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train['date']=pd.to_datetime(train[['year','month','day']],errors='coerce')\n/tmp/ipykernel_36/2917683.py:132: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train['in_Cluster']=train['in_Cluster'].astype(str)\n/tmp/ipykernel_36/2917683.py:133: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train['out_Cluster']=train['out_Cluster'].astype(str)\n/tmp/ipykernel_36/2917683.py:136: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train['in_Cluster']=encoder.transform(train['in_Cluster'])\n/tmp/ipykernel_36/2917683.py:138: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train['out_Cluster']=encoder.transform(train['out_Cluster'])\n/tmp/ipykernel_36/2917683.py:132: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train['in_Cluster']=train['in_Cluster'].astype(str)\n/tmp/ipykernel_36/2917683.py:133: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train['out_Cluster']=train['out_Cluster'].astype(str)\n/tmp/ipykernel_36/2917683.py:136: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train['in_Cluster']=encoder.transform(train['in_Cluster'])\n/tmp/ipykernel_36/2917683.py:138: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train['out_Cluster']=encoder.transform(train['out_Cluster'])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 特征选择\n\n+ 往features添加特征列名称就行","metadata":{}},{"cell_type":"code","source":"columns=[ 'vendor_id','distance','duration_log', 'distance_have',\n         'motorway', 'trunk', 'primary',\n       'secondary', 'tertiary', 'unclassified', 'residential',\n       'nTrafficSignals', 'nCrossing', 'nStop', 'nIntersection',\n       'pc', 'pickup_longitude', 'pickup_latitude','day_of_year',\n       'dropoff_longitude', 'dropoff_latitude', 'store_and_fwd_flag',\n       'month', 'weekday', \n          'hour', 'minute',\n       'real_hour', 'rush_hour', 'is_weekend', 'year', 'day', \n          'humidity', 'pressure', 'temperature',\n        'wind_speed',\n       'direction_bins', 'maximum temperature', 'minimum temperature',\n       'average temperature', 'precipitation', 'snow fall',\n         'snow depth',\n         'in_Cluster','out_Cluster',\n         \n         'speed','trip_duration'\n         ]\nfeatures=columns[:-2]","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:18:37.762210Z","iopub.execute_input":"2024-09-03T11:18:37.762735Z","iopub.status.idle":"2024-09-03T11:18:37.771303Z","shell.execute_reply.started":"2024-09-03T11:18:37.762691Z","shell.execute_reply":"2024-09-03T11:18:37.769620Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"# 模型训练\n\n+ 最终提交请使用get_oof这里的交叉验证模型\n+ API 使用也很简单，参考： \n\n```python\n%%time\nx=train[features]\ny=train.trip_duration\npred_train3,pred_test3=get_oof_ligGBM(x,y,test[features])\n```","metadata":{"execution":{"iopub.status.busy":"2024-09-03T10:34:18.218586Z","iopub.execute_input":"2024-09-03T10:34:18.219083Z","iopub.status.idle":"2024-09-03T10:34:18.261174Z","shell.execute_reply.started":"2024-09-03T10:34:18.219038Z","shell.execute_reply":"2024-09-03T10:34:18.259470Z"}}},{"cell_type":"code","source":"def get_oof_ligGBM(x_train,y_train,x_test,p=None):\n    \n    lgb_params = {\n'learning_rate': 0.1,\n'max_depth': 16,\n'num_leaves':1000, \n'objective': 'regression',\n'feature_fraction': 0.8,\n'bagging_fraction': 0.6,\n'max_bin': 1000\n,'verbosity': -1,\n    'metric':'rmse',\n        'verbose_eval':10\n} if p==None else p\n    \n    oof_train=np.zeros((x_train.shape[0],))\n    oof_test=np.zeros((x_test.shape[0],))\n\n\n    for i,(train_index,valid_index) in enumerate(kf.split(x_train,y_train)):\n        trn_x,trn_y=x_train.iloc[train_index],y_train.iloc[train_index]\n        val_x,val_y=x_train.iloc[valid_index],y_train.iloc[valid_index]\n        dtrn=lgb.Dataset(trn_x,trn_y)\n        dval=lgb.Dataset(val_x,val_y)\n        bst=lgb.train(lgb_params, dtrn, num_boost_round=1500,valid_sets=[dtrn,dval])\n        \n        oof_train[valid_index]=bst.predict(val_x)\n        oof_test+=bst.predict(x_test)/5\n    return oof_train.reshape(-1,1),oof_test.reshape(-1,1)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:23:31.189086Z","iopub.execute_input":"2024-09-03T11:23:31.189681Z","iopub.status.idle":"2024-09-03T11:23:31.204491Z","shell.execute_reply.started":"2024-09-03T11:23:31.189625Z","shell.execute_reply":"2024-09-03T11:23:31.202891Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"def get_oof_XGBoost(x_train,y_train,x_test,p=None):\n    # 算法参数\n    params = {\n        # 通用参数\n    'min_child_weight': 50,\n    'learning_rate': 0.05,\n    'colsample_bytree': 0.7,\n    'max_depth': 16,\n    'subsample': 0.8,\n    'booster' : 'gbtree',\n    'eval_metric': 'rmse',\n    'objective': 'reg:squarederror',\n    'colsample_bylevel': 0.7,\n    'silent':1,\n    'reg_alpha':1,\n        # 'eval_metric': 'auc'\n    } if p==None else p\n    \n    oof_train=np.zeros((x_train.shape[0],))\n    oof_test=np.zeros((x_test.shape[0],))\n\n\n    for i,(train_index,valid_index) in enumerate(kf.split(x_train,y_train)):\n        trn_x,trn_y=x_train.iloc[train_index],y_train.iloc[train_index]\n        val_x,val_y=x_train.iloc[valid_index],y_train.iloc[valid_index]\n        dtrn=xgb.DMatrix(trn_x,trn_y)\n        dval=xgb.DMatrix(val_x,val_y)\n        watchlist=[(dtrn,\"train\"),(dval,\"valid_data\")]\n        bst=xgb.train(params, dtrn, num_boost_round=7,evals=watchlist,early_stopping_rounds=50,verbose_eval=100)\n        oof_test+=bst.predict(xgb.DMatrix(x_test))/5\n        oof_train[valid_index]=bst.predict(xgb.DMatrix(val_x))\n\n    return oof_train.reshape(-1,1),oof_test.reshape(-1,1)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:23:36.351417Z","iopub.execute_input":"2024-09-03T11:23:36.351919Z","iopub.status.idle":"2024-09-03T11:23:36.367606Z","shell.execute_reply.started":"2024-09-03T11:23:36.351870Z","shell.execute_reply":"2024-09-03T11:23:36.365818Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"def get_oof_CatBoost(x_train,y_train,x_test,p=None):\n    # 算法参数\n    params={\n    'loss_function': 'RMSE', # 损失函数，取值RMSE, Logloss, MAE, CrossEntropy, Quantile, LogLinQuantile, Multiclass, MultiClassOneVsAll, MAPE, Poisson。默认Logloss。\n\n    'iterations': 700, # 最大迭代次数，默认500. 别名：num_boost_round, n_estimators, num_trees\n    'learning_rate': 0.1, # 学习速率,默认0.03 别名：eta\n    'random_seed': 2024, # 训练的随机种子，别名：random_state\n    'l2_leaf_reg': 1, # l2正则项，别名：reg_lambda\n    'bootstrap_type': 'Bernoulli', # 确定抽样时的样本权重，取值Bayesian、Bernoulli(伯努利实验)、MVS(仅支持cpu)、Poisson(仅支持gpu)、No（取值为No时，每棵树为简单随机抽样）;默认值GPU下为Bayesian、CPU下为MVS\n#     'bagging_temperature': 0,  # bootstrap_type=Bayesian时使用,取值为1时采样权重服从指数分布；取值为0时所有采样权重均等于1。取值范围[0，inf)，值越大、bagging就越激进\n    'subsample': 0.6, # 样本采样比率（行采样）\n    'sampling_frequency': 'PerTree', # 采样频率，取值PerTree（在构建每棵新树之前采样）、PerTreeLevel（默认值，在子树的每次分裂之前采样）；仅支持CPU\n    'use_best_model': True, # 让模型使用效果最优的子树棵树/迭代次数，使用验证集的最优效果对应的迭代次数（eval_metric：评估指标，eval_set：验证集数据），布尔类型可取值0，1（取1时要求设置验证集数据）\n    'best_model_min_trees': 50, # 最少子树棵树,和use_best_model一起使用\n    'depth': 10, # 树深，默认值6\n    'grow_policy': 'SymmetricTree', # 子树生长策略，取值SymmetricTree（默认值，对称树）、Depthwise（整层生长，同xgb）、Lossguide（叶子结点生长，同lgb）\n    'min_data_in_leaf': 500, # 叶子结点最小样本量\n#     'max_leaves': 12, # 最大叶子结点数量\n    'one_hot_max_size': 4, # 对唯一值数量<one_hot_max_size的类别型特征使用one-hot编码\n    'rsm': 0.6, # 列采样比率，别名colsample_bylevel 取值（0，1],默认值1\n    'nan_mode': 'Max', # 缺失值处理方法，取值Forbidden（不支持缺失值，输入包含缺失时会报错）、Min（处理为该列的最小值，比原最小值更小）、Max（同理）\n    'input_borders': None, # 特征数据边界（最大最小边界）、会影响缺失值的处理（nan_mode取值Min、Max时），默认值None、在训练时特征取值的最大最小值即为特征值边界\n    'boosting_type': 'Ordered', # 提升类型，取值Ordered（catboost特有的排序提升，在小数据集上效果可能更好，但是运行速度较慢）、Plain（经典提升）\n    'max_ctr_complexity':4, # 分类特征交叉的最高阶数，默认值4\n#     'logging_level':'Silent', # 模型训练过程的信息输出等级，取值Silent（不输出信息）、Verbose（默认值，输出评估指标、已训练时间、剩余时间等）、Info（输出额外信息、树的棵树）、Debug（debug信息）\n    'metric_period': 100, # 计算目标值、评估指标的频率，默认值1、即每次迭代都输出目标值、评估指标\n    'early_stopping_rounds': 50,\n    'border_count': 300, # 数值型特征的分箱数，别名max_bin，取值范围[1,65535]、默认值254（CPU下), # 设置提前停止训练，在得到最佳的评估结果后、再迭代n（参数值为n）次停止训练，默认值不启用\n    'feature_border_type': 'GreedyLogSum', # 数值型特征的分箱方法，取值Median、Uniform、UniformAndQuantiles、MaxLogSum、MinEntropy、GreedyLogSum（默认值）\n        'od_type': 'Iter',\n\n        \n} if p==None else p\n    \n    oof_train=np.zeros((x_train.shape[0],))\n    oof_test=np.zeros((x_test.shape[0],))\n\n\n    for i,(train_index,valid_index) in enumerate(kf.split(x_train,y_train)):\n        bst=CatBoostRegressor(**params)\n        trn_x,trn_y=x_train.iloc[train_index],y_train.iloc[train_index]\n        val_x,val_y=x_train.iloc[valid_index],y_train.iloc[valid_index]\n       \n        bst.fit(trn_x,trn_y,eval_set=(val_x,val_y))\n        oof_test+=bst.predict(x_test)/5\n        oof_train[valid_index]=bst.predict(val_x)\n\n    return oof_train.reshape(-1,1),oof_test.reshape(-1,1)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:18:47.654689Z","iopub.execute_input":"2024-09-03T11:18:47.655271Z","iopub.status.idle":"2024-09-03T11:18:47.670282Z","shell.execute_reply.started":"2024-09-03T11:18:47.655177Z","shell.execute_reply":"2024-09-03T11:18:47.668810Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":"#  结果提交\n+ queryScore是查询分数的\n+ makeRes是直接输出结果的\n\n用法：\n\n```python\n# queryScore\n%%time\nqueryScore(你的模型，训练集，测试集)\n```\n\n```python\n# makeRes\nmakeRes(预测结果，文件名)\n\nmakeRes(np.exp(pred3),'xgboost_1')\n\n```","metadata":{}},{"cell_type":"code","source":"def queryScore(model,train=None,test=None):\n    print(\"*\"*10)\n    print(\"Train shape\",trainXsplit[features].shape)\n    print(\"Score in Train %.10f\"%np.sqrt(MSE(model.predict(trainXsplit[features]),trainXsplit.trip_duration)))\n    print(\"Val shape\",testXsplit[features].shape)\n    print(\"*\"*10)\n    print(\"Score in Val %.10f\"%np.sqrt(MSE(model.predict(testXsplit[features]),testXsplit.trip_duration)))","metadata":{"execution":{"iopub.status.busy":"2024-09-03T10:56:40.303518Z","iopub.execute_input":"2024-09-03T10:56:40.303905Z","iopub.status.idle":"2024-09-03T10:56:40.320636Z","shell.execute_reply.started":"2024-09-03T10:56:40.303864Z","shell.execute_reply":"2024-09-03T10:56:40.319284Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def makeRes(pred,p):\n    submission = pd.DataFrame({'id': ori_test.id, 'trip_duration': np.nan})\n    submission.iloc[test_index,-1]=pred\n    submission.fillna(submission.trip_duration.mean(),inplace=True)\n    submission.to_csv(\"%s.csv\"%p,index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-03T10:56:40.322110Z","iopub.execute_input":"2024-09-03T10:56:40.322487Z","iopub.status.idle":"2024-09-03T10:56:40.334970Z","shell.execute_reply.started":"2024-09-03T10:56:40.322448Z","shell.execute_reply":"2024-09-03T10:56:40.333792Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"# 走一下流程\n+ 前面baseline都好了\n+ 只需要修改features ，构建特征和清洗数据即可","metadata":{}},{"cell_type":"code","source":"%%time \n_=train\nx,y=_[features],_.trip_duration\npred_train3,pred_test3=get_oof_XGBoost(x,y,test[features])","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:28:13.989054Z","iopub.execute_input":"2024-09-03T11:28:13.989603Z","iopub.status.idle":"2024-09-03T11:30:40.191992Z","shell.execute_reply.started":"2024-09-03T11:28:13.989555Z","shell.execute_reply":"2024-09-03T11:30:40.190583Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:28:18] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"silent\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[0]\ttrain-rmse:0.77107\tvalid_data-rmse:0.77078\n[6]\ttrain-rmse:0.63040\tvalid_data-rmse:0.63264\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:28:47] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"silent\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[0]\ttrain-rmse:0.77113\tvalid_data-rmse:0.77055\n[6]\ttrain-rmse:0.63042\tvalid_data-rmse:0.63258\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:29:15] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"silent\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[0]\ttrain-rmse:0.77046\tvalid_data-rmse:0.77323\n[6]\ttrain-rmse:0.62989\tvalid_data-rmse:0.63484\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:29:43] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"silent\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[0]\ttrain-rmse:0.77089\tvalid_data-rmse:0.77158\n[6]\ttrain-rmse:0.63033\tvalid_data-rmse:0.63335\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:30:15] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"silent\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[0]\ttrain-rmse:0.77123\tvalid_data-rmse:0.77027\n[6]\ttrain-rmse:0.63057\tvalid_data-rmse:0.63241\nCPU times: user 2min 17s, sys: 7.51 s, total: 2min 24s\nWall time: 2min 26s\n","output_type":"stream"}]},{"cell_type":"code","source":"makeRes(np.exp(pred_test3.reshape(-1)),'ligtGBM_1')","metadata":{"execution":{"iopub.status.busy":"2024-09-03T11:31:08.620897Z","iopub.execute_input":"2024-09-03T11:31:08.621368Z","iopub.status.idle":"2024-09-03T11:31:10.699931Z","shell.execute_reply.started":"2024-09-03T11:31:08.621324Z","shell.execute_reply":"2024-09-03T11:31:10.698468Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}